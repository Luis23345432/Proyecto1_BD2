# üìö Explicaci√≥n del Sistema de B√∫squeda de Texto Completo (Full-Text Search)

## üéØ ¬øQu√© es este sistema?

Es una implementaci√≥n de un **motor de b√∫squeda** similar a Google, pero para buscar en documentos de tu base de datos. Utiliza t√©cnicas avanzadas como:
- **√çndice Invertido**: estructura de datos que mapea palabras ‚Üí documentos
- **TF-IDF**: algoritmo para calcular la relevancia de documentos
- **Similitud de Coseno**: m√©trica para rankear resultados
- **SPIMI**: t√©cnica para construir √≠ndices grandes que no caben en RAM

---

## üìÅ Arquitectura de Archivos

### 1. **`preprocessor.py`** - Preprocesador de Texto
**¬øQu√© hace?**
Prepara el texto antes de indexarlo o buscarlo, realizando 4 pasos:

```
Texto original: "The quick DOGS are running!"
                    ‚Üì
1. Tokenizaci√≥n: ["the", "quick", "dogs", "are", "running"]
2. Min√∫sculas:   ["the", "quick", "dogs", "are", "running"]
3. Stopwords:    ["quick", "dogs", "running"]  (elimina "the", "are")
4. Stemming:     ["quick", "dog", "run"]       (ra√≠ces de palabras)
```

**Componentes principales:**
- `tokenize()`: divide texto en palabras
- `remove_stopwords()`: elimina palabras comunes sin significado ("el", "la", "de")
- `apply_stemming()`: reduce palabras a su ra√≠z ("corriendo" ‚Üí "corr")
- `preprocess()`: ejecuta todo el pipeline

**Ejemplo de uso:**
```python
preprocessor = TextPreprocessor(language='english')
tokens = preprocessor.preprocess("Machine Learning is amazing!")
# Resultado: ['machin', 'learn', 'amaz']
```

---

### 2. **`inverted_index.py`** - √çndice Invertido en Memoria (RAM)
**¬øQu√© hace?**
Crea una estructura de datos en RAM que permite b√∫squeda r√°pida:

```
Estructura del √çndice Invertido:
{
    'python': {
        'doc1': {'tf': 5, 'positions': [0, 10, 25, 30, 45]},
        'doc3': {'tf': 2, 'positions': [8, 20]}
    },
    'learning': {
        'doc1': {'tf': 3, 'positions': [5, 15, 35]},
        'doc2': {'tf': 1, 'positions': [12]}
    }
}
```

**Componentes principales:**
- `add_document()`: agrega un documento al √≠ndice
- `calculate_tf_idf()`: calcula pesos TF-IDF
- `search()`: busca documentos relevantes
- `save()` / `load()`: guarda/carga el √≠ndice desde disco

**Limitaci√≥n:** Solo funciona para datasets peque√±os que caben en RAM (< 500 MB)

---

### 3. **`spimi.py`** - SPIMI (Single-Pass In-Memory Indexing)
**¬øQu√© hace?**
Construye √≠ndices invertidos para **datasets grandes** que NO caben en RAM.

**Algoritmo SPIMI en 3 fases:**

#### **Fase 1: Construcci√≥n de Bloques**
```
Documents ‚Üí [Block 1] [Block 2] [Block 3] ... [Block N]
                ‚Üì         ‚Üì         ‚Üì             ‚Üì
            RAM llena  RAM llena RAM llena    RAM llena
            ‚Üí Guardar  ‚Üí Guardar ‚Üí Guardar  ‚Üí Guardar
```

Divide los documentos en bloques que s√≠ caben en RAM:
- Lee documentos uno por uno
- Construye √≠ndice en RAM hasta llenarla (ej: 100 MB)
- Guarda el bloque en disco (`block_0.pkl`, `block_1.pkl`, etc.)
- Limpia RAM y repite con siguientes documentos

#### **Fase 2: Merge de Bloques**
```
[Block 1] + [Block 2] + [Block 3] + ... + [Block N]
                    ‚Üì
            [√çndice Merged Final]
```

Combina todos los bloques en un √≠ndice unificado usando **merge sort**:
- Usa heap (cola de prioridad) para procesar t√©rminos en orden
- No carga todos los bloques en RAM a la vez
- Genera el √≠ndice final combinado

#### **Fase 3: C√°lculo TF-IDF y Normalizaci√≥n**
```
√çndice Merged ‚Üí Calcular IDF ‚Üí Calcular TF-IDF ‚Üí Normalizar ‚Üí Guardar bloques finales
```

- **IDF**: `log10(N / df)` donde N = total docs, df = docs con t√©rmino
- **TF-IDF**: `(1 + log10(tf)) * IDF`
- **Normalizaci√≥n**: divide por norma euclidiana del documento

**Componentes principales:**
- `build_index()`: ejecuta las 3 fases
- `_build_blocks()`: fase 1
- `_merge_blocks()`: fase 2
- `_calculate_tfidf()`: fase 3

**Archivos generados:**
```
data/spimi_blocks/
‚îú‚îÄ‚îÄ block_0.pkl          # Bloque 0 del √≠ndice normalizado
‚îú‚îÄ‚îÄ block_1.pkl          # Bloque 1 del √≠ndice normalizado
‚îú‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ doc_norms.pkl        # Normas euclidianas de documentos
‚îú‚îÄ‚îÄ doc_ids.pkl          # Mapeo ID num√©rico ‚Üí ID original
‚îú‚îÄ‚îÄ idf_scores.pkl       # Scores IDF de cada t√©rmino
‚îú‚îÄ‚îÄ term_to_block.pkl    # Mapeo t√©rmino ‚Üí archivo de bloque
‚îî‚îÄ‚îÄ index_info.pkl       # Metadatos del √≠ndice
```

---

### 4. **`spimi_helpers.py`** - Funciones Auxiliares para SPIMI
**¬øQu√© hace?**
Contiene las funciones matem√°ticas y de procesamiento para finalizar el √≠ndice SPIMI.

**Funciones principales:**
- `compute_idf_scores()`: calcula IDF = log10(N / df)
- `compute_tfidf_weights()`: calcula TF-IDF = (1 + log10(tf)) * IDF
- `compute_document_norms()`: norma = sqrt(Œ£ weight¬≤)
- `normalize_index_by_doc_norms()`: weight / norma
- `save_blocks_to_disk()`: guarda √≠ndice en bloques
- `create_term_to_block_mapping()`: mapea t√©rminos a bloques

---

### 5. **`cosine_search.py`** - Motor de B√∫squeda
**¬øQu√© hace?**
Busca documentos relevantes usando **similitud de coseno**.

**Algoritmo:**
```
1. Usuario escribe: "machine learning python"
2. Preprocesar consulta: ['machin', 'learn', 'python']
3. Calcular vector de consulta (TF-IDF de t√©rminos)
4. Para cada documento:
   - Cargar posting list del disco (solo t√©rminos de consulta)
   - Calcular producto punto: q ¬∑ d
   - Acumular score
5. Retornar Top-K documentos con mayor score
```

**Similitud de Coseno:**
```
cos(Œ∏) = (q ¬∑ d) / (||q|| √ó ||d||)

Donde:
- q = vector de consulta
- d = vector de documento
- ||v|| = norma euclidiana del vector
```

**Componentes principales:**
- `search()`: busca documentos relevantes
- `_load_posting_list_from_disk()`: carga solo los t√©rminos necesarios
- `_calculate_query_vector()`: vectoriza la consulta
- `_rank_documents()`: rankea por score descendente

**Optimizaci√≥n clave:** Solo carga del disco los bloques que contienen t√©rminos de la consulta (no todo el √≠ndice)

---

### 6. **`test_complete_search.py`** - Script de Pruebas
**¬øQu√© hace?**
Sistema de testing completo con men√∫ interactivo.

**Opciones del men√∫:**

#### **1. Consulta individual**
Prueba una consulta espec√≠fica:
```
Consulta: "machine learning"
Top-K: 10
‚Üí Muestra los 10 documentos m√°s relevantes con sus scores
```

**Salida:**
```
üîç CONSULTA: 'machine learning'
üìù Tokens: ['machin', 'learn']
‚è±Ô∏è  Tiempo de b√∫squeda: 15.32 ms
üìä Resultados encontrados: 10

üìÑ Top-10 Documentos:
  1. Doc: 12345
     Score: 0.8523 (85.23%)
  2. Doc: 67890
     Score: 0.7891 (78.91%)
  ...
```

#### **2. M√∫ltiples consultas de prueba**
Ejecuta varias consultas predefinidas y muestra estad√≠sticas:
```python
queries = [
    ("inteligencia artificial", 10),
    ("base de datos", 5),
    ("machine learning", 8),
]
```

**Salida:**
```
üìä ESTAD√çSTICAS GENERALES
Total de consultas: 3
Tiempo total: 45.67 ms
Tiempo promedio: 15.22 ms
Consulta m√°s r√°pida: 12.45 ms
Consulta m√°s lenta: 18.90 ms
```

#### **3. An√°lisis de rendimiento (diferentes K)**
Prueba la misma consulta con diferentes valores de K (Top-5, Top-10, Top-20, etc.):

**Salida:**
```
‚ö° AN√ÅLISIS DE RENDIMIENTO POR K
Consulta: 'python programming'

K          Tiempo (ms)     Resultados      ms/resultado
--------------------------------------------------------------
5          10.23           5               2.046
10         12.45           10              1.245
20         15.67           20              0.784
50         23.89           50              0.478
100        35.12           100             0.351
```

**Observaci√≥n:** M√°s resultados = m√°s tiempo, pero no lineal (optimizado)

#### **4. Pruebas de casos borde**
Prueba casos extremos:
- Consulta vac√≠a: ""
- T√©rminos inexistentes: "xyz123qweasd"
- Solo stopwords: "el la de"
- Una letra: "a"
- Consulta muy larga

**Utilidad:** Verificar que el sistema no falla en casos raros

#### **5. Modo interactivo**
Permite hacer b√∫squedas en tiempo real:
```
üîç Consulta: python machine learning
üìä Top-K (default 10): 5

[Muestra resultados]

üîç Consulta: base de datos
üìä Top-K (default 10): 10

[Muestra resultados]

üîç Consulta: exit
üëã ¬°Hasta luego!
```

Comandos especiales:
- `stats`: muestra estad√≠sticas del √≠ndice
- `exit` o `quit`: salir

#### **6. Comparar con b√∫squeda lineal**
Benchmark te√≥rico vs PostgreSQL:
```
üìä √çndice Invertido:
   Tiempo: 15.32 ms
   Resultados: 10

üìä B√∫squeda Lineal (PostgreSQL):
   Tiempo: [Ejecutar benchmark con PostgreSQL]
   
üí° Para comparaci√≥n completa:
   1. Carga el mismo dataset en PostgreSQL
   2. Crea √≠ndice GIN sobre tsvector
   3. Ejecuta consulta equivalente
   4. Compara tiempos y resultados
```

#### **7. Mostrar estad√≠sticas del √≠ndice**
Muestra informaci√≥n del √≠ndice construido:
```
üìä ESTAD√çSTICAS DEL √çNDICE
Total de documentos: 50,000
Total de t√©rminos: 125,000
Longitud promedio de doc: 150.23

Archivos en data/spimi_blocks:
  ‚Ä¢ block_0.pkl                    15.32 MB
  ‚Ä¢ block_1.pkl                    14.87 MB
  ‚Ä¢ doc_norms.pkl                   0.45 MB
  ‚Ä¢ doc_ids.pkl                     0.32 MB
  ‚Ä¢ idf_scores.pkl                  1.23 MB
  ‚Ä¢ term_to_block.pkl               0.78 MB
```

---

## üöÄ C√≥mo Probar el Sistema

### **Paso 1: Construir el √çndice SPIMI**

Primero necesitas tener datos. Opciones:

**Opci√≥n A: Usar dataset de lyrics (canciones)**
```powershell
# Aseg√∫rate de que existan archivos en datasets/lyrics/
python text_search/spimi.py
```

**Opci√≥n B: Importar datos desde tu base de datos**
```python
# Ejemplo: leer desde tu tabla
from text_search.spimi import SPIMIIndexer
from text_search.preprocessor import TextPreprocessor

preprocessor = TextPreprocessor()
indexer = SPIMIIndexer(output_dir='data/spimi_blocks', block_size_mb=100)

def document_generator():
    # Aqu√≠ conectas a tu BD y lees documentos
    for doc_id, text in tu_consulta_sql():
        tokens = preprocessor.preprocess(text)
        yield (doc_id, tokens)

indexer.build_index(document_generator())
```

**Salida esperada:**
```
============================================================
üî® INICIANDO CONSTRUCCI√ìN SPIMI
============================================================
üßπ Limpiando archivos anteriores...

üì¶ FASE 1: Construcci√≥n de Bloques
  ‚Üí Bloque 0: 10,000 docs procesados...
  ‚Üí Bloque 1: 10,000 docs procesados...
  ...
  ‚úì Total: 5 bloques creados

üîÄ FASE 2: Merge de Bloques
  ‚Üí Merging 5 bloques...
  ‚úì √çndice merged creado

üìä FASE 3: C√°lculo TF-IDF
  ‚Üí Calculando IDF...
  ‚Üí Calculando TF-IDF...
  ‚Üí Normalizando vectores...
  ‚úì √çndice optimizado

‚úÖ √çndice SPIMI construido exitosamente
============================================================
```

**Tiempo estimado:** 
- 10,000 docs: ~30 segundos
- 100,000 docs: ~5 minutos
- 1,000,000 docs: ~30-40 minutos

---

### **Paso 2: Ejecutar el Sistema de Pruebas**

```powershell
python text_search/test_complete_search.py
```

**Aparecer√° el men√∫:**
```
============================================================
MEN√ö DE PRUEBAS
============================================================
1. Consulta individual
2. M√∫ltiples consultas de prueba
3. An√°lisis de rendimiento (diferentes K)
4. Pruebas de casos borde
5. Modo interactivo
6. Comparar con b√∫squeda lineal
7. Mostrar estad√≠sticas del √≠ndice
8. Salir
============================================================

Selecciona una opci√≥n: 
```

---

### **Paso 3: Ejemplos de Uso**

#### **Ejemplo 1: B√∫squeda r√°pida (Opci√≥n 1)**
```
Selecciona una opci√≥n: 1

üîç Ingresa tu consulta: machine learning algorithms
üìä Top-K (default 10): 5

[Muestra los 5 documentos m√°s relevantes]
```

#### **Ejemplo 2: Modo interactivo (Opci√≥n 5)**
```
Selecciona una opci√≥n: 5

üîé MODO INTERACTIVO
Comandos:
  - Escribe tu consulta y presiona Enter
  - 'exit' o 'quit' para salir
  - 'stats' para ver estad√≠sticas del √≠ndice

üîç Consulta: python programming
üìä Top-K (default 10): 10

[Resultados...]

üîç Consulta: deep learning neural networks
üìä Top-K (default 10): 5

[Resultados...]

üîç Consulta: exit
üëã ¬°Hasta luego!
```

#### **Ejemplo 3: Benchmark (Opci√≥n 3)**
```
Selecciona una opci√≥n: 3

üîç Ingresa tu consulta: artificial intelligence

[Muestra tabla de rendimiento por K]
```

---

## üî¨ Entendiendo los Resultados

### **Score de Similitud**
```
Score: 0.8523 (85.23%)
```
- **0.0 - 0.3**: Relevancia baja (documento apenas relacionado)
- **0.3 - 0.6**: Relevancia media (documento algo relacionado)
- **0.6 - 0.8**: Relevancia alta (documento muy relacionado)
- **0.8 - 1.0**: Relevancia muy alta (documento extremadamente relevante)

### **Tiempo de B√∫squeda**
```
‚è±Ô∏è  Tiempo de b√∫squeda: 15.32 ms
```
- **< 20 ms**: Excelente (Google ~50-200 ms)
- **20-100 ms**: Bueno
- **100-500 ms**: Aceptable
- **> 500 ms**: Necesita optimizaci√≥n

### **Interpretaci√≥n de Tokens**
```
Consulta original: "The running dogs are fast!"
üìù Tokens: ['run', 'dog', 'fast']
```
- Se eliminaron stopwords: "The", "are"
- Se aplic√≥ stemming: "running" ‚Üí "run", "dogs" ‚Üí "dog"
- Esto permite encontrar variaciones: "dog", "dogs", "running", "run", "runs"

---

## ‚öôÔ∏è Ajustes y Configuraci√≥n

### **Cambiar idioma:**
```python
# En preprocessor.py
preprocessor = TextPreprocessor(language='spanish')  # o 'english', 'french', etc.
```

### **Desactivar stemming:**
```python
preprocessor = TextPreprocessor(use_stemming=False)
```

### **Ajustar tama√±o de bloques SPIMI:**
```python
# M√°s peque√±o = menos RAM, m√°s bloques
indexer = SPIMIIndexer(output_dir='...', block_size_mb=50)

# M√°s grande = m√°s RAM, menos bloques (m√°s r√°pido)
indexer = SPIMIIndexer(output_dir='...', block_size_mb=200)
```

---

## üêõ Soluci√≥n de Problemas

### **Error: "√çndice no encontrado"**
```
‚ùå No se encontr√≥ el directorio del √≠ndice
```
**Soluci√≥n:** Construye el √≠ndice primero:
```powershell
python text_search/spimi.py
```

### **Error: "Import nltk could not be resolved"**
```
Import "nltk" could not be resolved
```
**Soluci√≥n:** Instala nltk en el entorno correcto:
```powershell
conda install nltk
# o
pip install nltk
```

### **Consulta sin resultados**
```
üìä Resultados encontrados: 0
```
**Causas posibles:**
1. T√©rminos demasiado espec√≠ficos o inexistentes
2. Todos los t√©rminos son stopwords
3. El √≠ndice no contiene documentos relevantes

**Soluci√≥n:** Prueba con consultas m√°s generales

### **Tiempo de b√∫squeda muy lento (> 1 segundo)**
**Causas posibles:**
1. √çndice muy grande en disco lento
2. Muchos t√©rminos en la consulta
3. Disco duro mec√°nico en vez de SSD

**Soluci√≥n:**
- Usa SSD
- Reduce el n√∫mero de t√©rminos en la consulta
- Aumenta `block_size_mb` al construir el √≠ndice

---

## üìä Comparaci√≥n: RAM vs SPIMI

| Caracter√≠stica | InvertedIndex (RAM) | SPIMI (Disco) |
|----------------|---------------------|---------------|
| Dataset peque√±o (< 10K docs) | ‚ö° Muy r√°pido | üê¢ Innecesario |
| Dataset mediano (10K-100K) | ‚ö†Ô∏è Puede funcionar | ‚úÖ Recomendado |
| Dataset grande (> 100K) | ‚ùå No cabe en RAM | ‚úÖ Funciona bien |
| Tiempo construcci√≥n | R√°pido | Moderado |
| Tiempo b√∫squeda | Muy r√°pido | R√°pido |
| Uso de RAM | Alto | Bajo |

---

## üéì Conceptos Clave

### **TF-IDF (Term Frequency - Inverse Document Frequency)**
Mide qu√© tan importante es una palabra para un documento:
- **TF**: ¬øCu√°ntas veces aparece en el documento?
- **IDF**: ¬øQu√© tan rara es la palabra en todos los documentos?

Ejemplo:
- "python" aparece 10 veces en doc1 ‚Üí TF alto
- "python" aparece en 5,000 de 50,000 docs ‚Üí IDF medio
- Palabra com√∫n "el" aparece en 49,000 docs ‚Üí IDF muy bajo (filtrada)

### **Similitud de Coseno**
Mide el √°ngulo entre dos vectores:
```
cos(Œ∏) = 0   ‚Üí Documentos completamente diferentes
cos(Œ∏) = 0.5 ‚Üí Documentos algo relacionados
cos(Œ∏) = 1.0 ‚Üí Documentos id√©nticos
```

### **√çndice Invertido**
Estructura de datos invertida:
```
Normal: Doc1 ‚Üí ["python", "programming", "tutorial"]
Invertido: "python" ‚Üí [Doc1, Doc5, Doc10]
           "programming" ‚Üí [Doc1, Doc3, Doc8]
```

Permite b√∫squeda r√°pida: O(t√©rminos en consulta) en vez de O(todos los documentos)

---

## üéØ Conclusi√≥n

Este sistema implementa un motor de b√∫squeda profesional con:
- ‚úÖ Preprocesamiento de texto (tokenizaci√≥n, stemming, stopwords)
- ‚úÖ √çndice invertido optimizado (SPIMI para grandes datasets)
- ‚úÖ Ranking por relevancia (TF-IDF + Similitud de Coseno)
- ‚úÖ B√∫squeda eficiente en disco (solo carga lo necesario)
- ‚úÖ Sistema de pruebas completo

**Casos de uso:**
- B√∫squeda en documentos legales
- Motor de b√∫squeda de productos
- B√∫squeda de art√≠culos cient√≠ficos
- Sistema de recomendaci√≥n basado en texto
- An√°lisis de sentimientos en reviews
- B√∫squeda en base de conocimiento

¬°Ahora puedes buscar en millones de documentos en milisegundos! üöÄ
