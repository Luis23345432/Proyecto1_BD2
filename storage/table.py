"""
Clase Table con soporte correcto para ISAM:
- Los √≠ndices se construyen correctamente al inicio
- INSERTs van al √≠ndice base si hay espacio, overflow si est√° lleno
- build_indexes() reconstruye desde datos existentes (para CSV loads)
"""

from __future__ import annotations

import os
import json
from typing import Any, Dict, List, Optional, Tuple

from core.schema import TableSchema
from core.types import convert_value
from core.records import Record
from indexes import BPlusTree
from indexes.ISAM import ISAM
from indexes.AVL import AVL
from indexes.ExtHashing import ExtHashing
from indexes.Rtree import RTreeIndex
from datafile import DataFile
from metrics import stats


class Table:
    def __init__(self, base_dir: str, schema: TableSchema, page_size: int = 4096):
        self.base_dir = os.path.abspath(base_dir)
        self.schema = schema
        self.page_size = page_size
        os.makedirs(self.base_dir, exist_ok=True)
        self.data_path = os.path.join(self.base_dir, "data.dat")
        self.schema_path = os.path.join(self.base_dir, "schema.json")
        self.index_dir = os.path.join(self.base_dir, "indexes")
        os.makedirs(self.index_dir, exist_ok=True)

        # almacenamiento
        self.datafile = DataFile(self.data_path, page_size=self.page_size)

        # √≠ndices por columna
        self.indexes: Dict[str, Any] = {}
        self._initialize_indexes()

        # guardar schema si no existe
        if not os.path.exists(self.schema_path):
            self.schema.save(self.schema_path)

    def _initialize_indexes(self):
        """Inicializa o carga √≠ndices desde disco."""
        for col_name, idx_type in self.schema.indexes.items():
            idx_path = os.path.join(self.index_dir, f"{col_name}.idx")
            idx_obj = None

            # Intentar cargar √≠ndice existente
            if os.path.exists(idx_path):
                try:
                    if idx_type.name.lower() == 'btree':
                        idx_obj = BPlusTree.load_idx(idx_path)
                    elif idx_type.name.lower() == 'isam':
                        idx_obj = ISAM.load_idx(idx_path)
                    elif idx_type.name.lower() == 'hash':
                        idx_obj = ExtHashing.load_idx(idx_path)
                    elif idx_type.name.lower() == 'rtree':
                        idx_obj = RTreeIndex.load_idx(idx_path)
                    else:
                        idx_obj = AVL.load_idx(idx_path)
                    print(f"‚úÖ √çndice {idx_type.name} cargado para columna '{col_name}'")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error cargando √≠ndice {col_name}: {e}")
                    idx_obj = None

            # Crear nuevo √≠ndice si no existe
            if idx_obj is None:
                is_clustered = self.schema.get_column(col_name).primary_key
                if idx_type.name.lower() == 'btree':
                    idx_obj = BPlusTree(degree=5, is_clustered=is_clustered)
                elif idx_type.name.lower() == 'isam':
                    # ISAM con page_size para factor de bloque
                    idx_obj = ISAM(page_size=10, is_clustered=is_clustered)
                    print(f"üî® ISAM creado para '{col_name}' (page_size=10)")
                elif idx_type.name.lower() == 'hash':
                    idx_obj = ExtHashing(is_clustered=is_clustered)
                elif idx_type.name.lower() == 'rtree':
                    idx_obj = RTreeIndex(dimensions=self._infer_dimensions_for(col_name))
                else:
                    idx_obj = AVL(is_clustered=is_clustered)

            self.indexes[col_name] = idx_obj

    def build_indexes_from_datafile(self):
        """
        Construye los √≠ndices desde los datos existentes en el datafile.
        CR√çTICO para ISAM: esto construye el √≠ndice base est√°tico.
        Debe llamarse:
        - Despu√©s de cargar CSV bulk
        - Al reconstruir √≠ndices manualmente
        """
        print(f"üî® Construyendo √≠ndices desde datafile para '{self.schema.name}'...")

        # Recolectar todos los datos del datafile
        all_records: List[Tuple[Tuple[int, int], Dict[str, Any]]] = []

        try:
            pc = self.datafile.page_count()
        except Exception:
            print("‚ö†Ô∏è No hay p√°ginas en el datafile")
            return

        # Leer todos los registros
        for page_id in range(pc):
            page = self.datafile.read_page(page_id)
            records = page.iter_records()
            for slot, rec_dict in enumerate(records):
                rid = (page_id, slot)
                all_records.append((rid, rec_dict))

        print(f"üìä Total de registros en datafile: {len(all_records)}")

        # Reconstruir cada √≠ndice
        for col_name, idx in self.indexes.items():
            idx_type = self.schema.indexes[col_name].name.lower()

            if idx_type == 'isam':
                # ISAM: construir con build_from_pairs (estructura est√°tica base)
                pairs = []
                for rid, rec_dict in all_records:
                    key = rec_dict.get(col_name)
                    if key is not None:
                        pairs.append((key, rid))

                if pairs:
                    print(f"üî® Construyendo ISAM para '{col_name}' con {len(pairs)} pares...")
                    idx.build_from_pairs(pairs)
                    stats_info = idx.get_stats()
                    print(f"‚úÖ ISAM construido: {stats_info}")
                else:
                    print(f"‚ö†Ô∏è No hay datos para ISAM en '{col_name}'")

            elif idx_type == 'btree':
                # BTree: inserci√≥n incremental
                for rid, rec_dict in all_records:
                    key = rec_dict.get(col_name)
                    if key is not None:
                        idx.add(key, rid)
                print(f"‚úÖ BTree construido para '{col_name}' con {len(all_records)} registros")

            elif idx_type == 'rtree':
                # RTree: datos espaciales
                for rid, rec_dict in all_records:
                    key = rec_dict.get(col_name)
                    if key is not None:
                        if not isinstance(key, (list, tuple)):
                            if isinstance(key, str):
                                parts = [p.strip() for p in key.split(',')]
                                key = [float(p) for p in parts]
                        idx.add(key, rid)
                print(f"‚úÖ RTree construido para '{col_name}' con {len(all_records)} registros")

            else:
                # Otros √≠ndices (AVL, Hash)
                for rid, rec_dict in all_records:
                    key = rec_dict.get(col_name)
                    if key is not None:
                        idx.add(key, rid)
                print(f"‚úÖ {idx_type.upper()} construido para '{col_name}'")

        for col_name, idx in self.indexes.items():
            if isinstance(idx, ISAM):
                stats_info = idx.get_stats()
                print(f"\nüìä ISAM Stats para '{col_name}':")
                print(f"   P√°ginas base: {stats_info['base_pages']}")
                print(f"   Registros base: {stats_info['base_records']}")
                print(f"   Keys √≠ndice: {idx.keys[:10]}")  # primeras 10
                if idx.pages:
                    print(f"   Primeros records de p√°gina 0: {idx.pages[0].records[:3]}")

        # Guardar √≠ndices en disco
        self._save_indexes()
        print("üíæ √çndices guardados en disco")

    def _save_indexes(self):
        """Persiste todos los √≠ndices en disco."""
        for col_name, tree in self.indexes.items():
            idx_path = os.path.join(self.index_dir, f"{col_name}.idx")
            tree.save_idx(idx_path)

    def _infer_dimensions_for(self, column: str) -> int:
        try:
            col = self.schema.get_column(column)
            vtype = col.col_type
            if vtype.name == 'ARRAY_FLOAT':
                return 2
        except Exception:
            pass
        return 2

    def insert(self, values: Dict[str, Any]) -> Tuple[int, int]:
        """
        Inserta un registro en la tabla.
        - Primero inserta en el datafile
        - Luego actualiza todos los √≠ndices
        - Para ISAM: si no hay √≠ndice base construido, va a overflow
        """
        stats.inc("table.insert.calls")
        with stats.timer("table.insert.time"):
            # Crear registro y validar tipos
            rec = Record(self.schema, values)
            rec_dict = rec.to_dict()

            # Insertar en datafile (storage f√≠sico)
            rid = self.datafile.insert_clustered(rec_dict)

            # Actualizar todos los √≠ndices
            for col in self.schema.columns:
                if col.name in self.indexes:
                    key = rec.values[col.name]
                    if key is None:
                        continue

                    tree = self.indexes[col.name]

                    try:
                        if isinstance(tree, RTreeIndex):
                            # RTree necesita coordenadas como lista
                            if not isinstance(key, (list, tuple)):
                                if isinstance(key, str):
                                    parts = [p.strip() for p in key.split(',')]
                                    key = [float(p) for p in parts]
                            tree.add(key, rid)
                        else:
                            # BTree, ISAM, AVL, Hash
                            tree.add(key, rid)
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error actualizando √≠ndice {col.name}: {e}")

            # Guardar √≠ndices despu√©s de cada inserci√≥n
            self._save_indexes()
            return rid

    def insert_bulk(self, values_list: List[Dict[str, Any]], rebuild_indexes: bool = True) -> List[Tuple[int, int]]:
        """
        Inserta m√∫ltiples registros de forma eficiente.

        Args:
            values_list: Lista de diccionarios con valores a insertar
            rebuild_indexes: Si True, reconstruye √≠ndices al final (RECOMENDADO para bulk load)

        Returns:
            Lista de RIDs insertados

        Estrategia:
            1. Desactiva √≠ndices temporalmente
            2. Inserta todos los registros en datafile
            3. Reconstruye todos los √≠ndices desde datafile (√≥ptimo para ISAM, BTree, etc.)
        """
        stats.inc("table.insert.bulk")
        with stats.timer("table.insert.bulk.time"):
            rids = []

            if rebuild_indexes:
                # MODO BULK: Desactivar √≠ndices temporalmente
                print(f"üî® Insertando {len(values_list)} registros en modo BULK...")
                original_indexes = self.indexes
                self.indexes = {}  # Desactivar √≠ndices

                # Insertar todos los registros en datafile
                for values in values_list:
                    rec = Record(self.schema, values)
                    rec_dict = rec.to_dict()
                    rid = self.datafile.insert_clustered(rec_dict)
                    rids.append(rid)

                # Restaurar √≠ndices
                self.indexes = original_indexes

                # Reconstruir todos los √≠ndices desde datafile
                print(f"‚úÖ {len(rids)} registros insertados en datafile")
                print(f"üî® Reconstruyendo √≠ndices desde datafile...")
                self.build_indexes_from_datafile()

            else:
                # MODO INCREMENTAL: Insertar uno por uno (actualiza √≠ndices)
                print(f"‚ö†Ô∏è Insertando {len(values_list)} registros en modo INCREMENTAL (lento)...")
                for values in values_list:
                    rid = self.insert(values)  # Usa insert() normal
                    rids.append(rid)

            return rids


    def _pick_index(self, column: str) -> Optional[Any]:
        """Retorna el √≠ndice para una columna si existe."""
        return self.indexes.get(column)

    def search(self, column: str, key: Any) -> List[Dict[str, Any]]:
        """B√∫squeda exacta usando √≠ndice o full scan."""
        stats.inc("table.search.calls")
        with stats.timer("table.search.time"):
            # Convertir key al tipo correcto
            try:
                col = self.schema.get_column(column)
                key = convert_value(col.col_type, key)
            except Exception:
                pass

            tree = self._pick_index(column)

            if not tree:
                # Sin √≠ndice: full scan
                print(f"‚ö†Ô∏è No hay √≠ndice para '{column}', haciendo full scan")
                out: List[Dict[str, Any]] = []
                try:
                    pc = self.datafile.page_count()
                except Exception:
                    return []
                for pid in range(pc):
                    page = self.datafile.read_page(pid)
                    recs = page.iter_records()
                    for r in recs:
                        if r.get(column) == key:
                            out.append(r)
                return out

            # Buscar usando √≠ndice
            print(f"üîç Buscando en {type(tree).__name__} columna='{column}', key={key}")
            rids = tree.search(key)
            print(f"üîç √çndice retorn√≥ {len(rids)} RIDs")

            # Recuperar registros completos
            results = [self.fetch_by_rid(rid) for rid in rids]
            print(f"üîç Registros recuperados: {len(results)}")
            return results

    def range_search(self, column: str, begin_key: Any, end_key: Any) -> List[Dict[str, Any]]:
        """B√∫squeda por rango usando √≠ndice."""
        stats.inc("table.range.calls")
        with stats.timer("table.range.time"):
            # Convertir keys al tipo correcto
            try:
                col = self.schema.get_column(column)
                begin_key = convert_value(col.col_type, begin_key)
                end_key = convert_value(col.col_type, end_key)
            except Exception:
                pass

            tree = self._pick_index(column)
            if not tree:
                print(f"‚ö†Ô∏è No hay √≠ndice para '{column}'")
                return []

            if isinstance(tree, RTreeIndex):
                print(f"‚ö†Ô∏è RTree no soporta range_search tradicional")
                rids = []
            else:
                print(f"üîç Range search en {type(tree).__name__}: [{begin_key}, {end_key}]")
                rids = tree.range_search(begin_key, end_key)
                print(f"üîç Range retorn√≥ {len(rids)} RIDs")

            return [self.fetch_by_rid(rid) for rid in rids]

    def range_radius(self, column: str, center: Any, radius: float) -> List[Dict[str, Any]]:
        """B√∫squeda espacial por radio (RTree)."""
        tree = self._pick_index(column)
        if not tree or not isinstance(tree, RTreeIndex):
            return []
        if not isinstance(center, (list, tuple)):
            if isinstance(center, str):
                parts = [p.strip() for p in center.split(',')]
                center = [float(p) for p in parts]
        rids = tree.range_search_radius(center, float(radius))
        return [self.fetch_by_rid(rid) for rid in rids]

    def knn(self, column: str, center: Any, k: int) -> List[Dict[str, Any]]:
        """K vecinos m√°s cercanos (RTree)."""
        tree = self._pick_index(column)
        if not tree or not isinstance(tree, RTreeIndex):
            return []
        if not isinstance(center, (list, tuple)):
            if isinstance(center, str):
                parts = [p.strip() for p in center.split(',')]
                center = [float(p) for p in parts]
        rids = tree.knn(center, int(k))
        return [self.fetch_by_rid(rid) for rid in rids]

    def delete(self, column: str, key: Any) -> int:
        """Elimina registros por clave."""
        stats.inc("table.delete.calls")
        with stats.timer("table.delete.time"):
            tree = self._pick_index(column)
            if not tree:
                return 0
            rids = tree.search(key)
            deleted = len(rids)
            tree.remove(key)
            self._save_indexes()
            return deleted

    def fetch_by_rid(self, rid: Tuple[int, int]) -> Dict[str, Any]:
        """Recupera un registro por su RID (page_id, slot)."""
        page_id, slot = rid
        rec = self.datafile.read_record(page_id, slot)
        return rec or {}

    def get_query_stats(self) -> Dict[str, Any]:
        """Obtiene estad√≠sticas de operaciones de √≠ndices."""
        all_stats = {}
        for col_name, idx in self.indexes.items():
            idx_type = self.schema.indexes[col_name].name.lower()
            all_stats[col_name] = {
                "type": idx_type,
                "operations": {
                    "search": {
                        "count": stats.get_counter(f"index.{idx_type}.search"),
                        "time_ms": round(stats.get_time_ms(f"index.{idx_type}.search.time"), 3),
                    },
                    "range": {
                        "count": stats.get_counter(f"index.{idx_type}.range"),
                        "time_ms": round(stats.get_time_ms(f"index.{idx_type}.range.time"), 3),
                    },
                    "add": {
                        "count": stats.get_counter(f"index.{idx_type}.add"),
                        "time_ms": round(stats.get_time_ms(f"index.{idx_type}.add.time"), 3),
                    },
                    "remove": {
                        "count": stats.get_counter(f"index.{idx_type}.remove"),
                        "time_ms": round(stats.get_time_ms(f"index.{idx_type}.remove.time"), 3),
                    },
                }
            }
        return all_stats

    def reset_stats(self):
        """Resetea contadores de m√©tricas."""
        stats.reset()