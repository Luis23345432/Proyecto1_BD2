"""
Script para construir el Ã­ndice SPIMI desde un archivo CSV
Uso: python text_search/build_index_from_csv.py
"""

import os
import sys
import csv
from pathlib import Path

# Agregar path si es necesario
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from text_search.spimi import SPIMIIndexer
from text_search.preprocessor import TextPreprocessor


def list_available_csvs():
    """Lista todos los CSVs disponibles en el proyecto"""
    csv_files = []
    
    # Buscar en directorios comunes
    search_dirs = [
        'postman',
        'datasets',
        'datasets/lyrics',
        '.'
    ]
    
    for dir_path in search_dirs:
        if os.path.exists(dir_path):
            for file in os.listdir(dir_path):
                if file.endswith('.csv'):
                    csv_files.append(os.path.join(dir_path, file))
    
    return csv_files


def preview_csv(csv_path, num_rows=5):
    """Muestra una preview del CSV"""
    print(f"\nğŸ“„ Preview de: {csv_path}")
    print("=" * 80)
    
    try:
        with open(csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            headers = reader.fieldnames
            
            print(f"ğŸ“‹ Columnas: {', '.join(headers)}")
            print(f"\nğŸ“Š Primeras {num_rows} filas:")
            print("-" * 80)
            
            for i, row in enumerate(reader):
                if i >= num_rows:
                    break
                print(f"\nFila {i+1}:")
                for key, value in row.items():
                    # Truncar valores largos
                    value_str = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                    print(f"  {key}: {value_str}")
            
            # Contar total de filas
            f.seek(0)
            next(f)  # Skip header
            total_rows = sum(1 for _ in f)
            print(f"\nğŸ“Š Total de filas en el archivo: {total_rows}")
            
    except Exception as e:
        print(f"âŒ Error leyendo CSV: {e}")
        return None
    
    return headers


def select_text_columns(headers):
    """Permite al usuario seleccionar quÃ© columnas usar para indexaciÃ³n"""
    print("\nğŸ“ Selecciona las columnas que contienen TEXTO para indexar:")
    print("   (Puedes seleccionar mÃºltiples columnas, se concatenarÃ¡n)")
    print("-" * 80)
    
    for i, header in enumerate(headers, 1):
        print(f"  {i}. {header}")
    
    print("\nğŸ’¡ Ejemplo: Si quieres usar columna 1 y 3, escribe: 1,3")
    selected = input("\nColumnas a usar (separadas por coma): ").strip()
    
    try:
        indices = [int(x.strip()) - 1 for x in selected.split(',')]
        selected_cols = [headers[i] for i in indices if 0 <= i < len(headers)]
        
        if not selected_cols:
            print("âš ï¸  No se seleccionaron columnas vÃ¡lidas")
            return None
        
        print(f"\nâœ“ Columnas seleccionadas: {', '.join(selected_cols)}")
        return selected_cols
        
    except Exception as e:
        print(f"âŒ Error: {e}")
        return None


def build_index_from_csv(csv_path, text_columns, output_dir='data/spimi_blocks', 
                         block_size_mb=100, max_docs=None, language='english'):
    """
    Construye el Ã­ndice SPIMI desde un CSV
    
    Args:
        csv_path: Ruta al archivo CSV
        text_columns: Lista de columnas a concatenar para indexar
        output_dir: Directorio de salida para el Ã­ndice
        block_size_mb: TamaÃ±o de bloque en MB
        max_docs: MÃ¡ximo de documentos a procesar (None = todos)
        language: Idioma para stopwords ('english', 'spanish', etc.)
    """
    print("\n" + "=" * 80)
    print("ğŸš€ INICIANDO CONSTRUCCIÃ“N DEL ÃNDICE")
    print("=" * 80)
    print(f"ğŸ“ Archivo: {csv_path}")
    print(f"ğŸ“ Columnas: {', '.join(text_columns)}")
    print(f"ğŸ’¾ Salida: {output_dir}")
    print(f"ğŸŒ Idioma: {language}")
    print(f"ğŸ“¦ TamaÃ±o de bloque: {block_size_mb} MB")
    if max_docs:
        print(f"âš ï¸  LÃ­mite: {max_docs} documentos (para prueba)")
    print("=" * 80)
    
    # Inicializar componentes
    indexer = SPIMIIndexer(output_dir=output_dir, block_size_mb=block_size_mb, language=language)
    preprocessor = TextPreprocessor(language=language, use_stemming=True)
    
    # Diccionario para guardar metadata de documentos
    doc_metadata = {}
    
    # Generador de documentos
    def document_generator():
        """Lee el CSV y genera (doc_id, tokens)"""
        docs_processed = 0
        
        try:
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                headers = reader.fieldnames
                
                print("\nğŸ“– Leyendo documentos...")
                
                for i, row in enumerate(reader):
                    # Concatenar columnas seleccionadas
                    text_parts = [str(row.get(col, '')) for col in text_columns]
                    text = ' '.join(text_parts)
                    
                    # Generar ID Ãºnico
                    doc_id = f"doc_{i+1}"
                    
                    # Guardar metadata del documento (nombre, datos originales)
                    # Intentar encontrar una columna "name" o "title" para mostrar
                    display_name = None
                    for col in ['name', 'title', 'nombre', 'titulo']:
                        if col in row and row[col]:
                            display_name = row[col]
                            break
                    
                    if not display_name:
                        # Si no hay columna de nombre, usar la primera columna textual
                        display_name = row.get(headers[0], doc_id) if headers else doc_id
                    
                    doc_metadata[doc_id] = {
                        'name': display_name,
                        'data': row  # Guardar todos los campos originales
                    }
                    
                    # Preprocesar texto
                    tokens = preprocessor.preprocess(text)
                    
                    # Solo retornar si hay tokens
                    if tokens:
                        yield doc_id, tokens
                        docs_processed += 1
                        
                        # Mostrar progreso
                        if docs_processed % 1000 == 0:
                            print(f"  âœ“ {docs_processed} documentos procesados...")
                    
                    # Limitar si se especificÃ³ max_docs
                    if max_docs and docs_processed >= max_docs:
                        print(f"\nâš ï¸  LÃ­mite alcanzado: {max_docs} documentos")
                        break
                
                print(f"\nâœ… Total procesado: {docs_processed} documentos")
                
        except Exception as e:
            print(f"\nâŒ Error leyendo CSV: {e}")
            import traceback
            traceback.print_exc()
    
    # Construir Ã­ndice completo
    try:
        final_path = indexer.build_complete_index(document_generator())
        
        # Guardar metadata de documentos
        import pickle
        metadata_path = os.path.join(output_dir, 'doc_metadata.pkl')
        with open(metadata_path, 'wb') as f:
            pickle.dump(doc_metadata, f)
        print(f"\nğŸ’¾ Metadata guardada: {len(doc_metadata)} documentos")
        
        print("\n" + "=" * 80)
        print("âœ… ÃNDICE CONSTRUIDO EXITOSAMENTE")
        print("=" * 80)
        print(f"ğŸ“ UbicaciÃ³n: {output_dir}")
        
        # Verificar archivos generados
        print("\nğŸ“‹ Archivos generados:")
        required_files = [
            'doc_norms.pkl',
            'doc_ids.pkl',
            'idf_scores.pkl',
            'term_to_block.pkl',
            'index_info.pkl'
        ]
        
        total_size = 0
        for filename in required_files:
            path = os.path.join(output_dir, filename)
            if os.path.exists(path):
                size_bytes = os.path.getsize(path)
                total_size += size_bytes
                
                # Mostrar en KB si es muy pequeÃ±o
                if size_bytes < 1024 * 1024:  # < 1 MB
                    size_kb = size_bytes / 1024
                    print(f"  âœ“ {filename:<25} {size_kb:>8.2f} KB")
                else:
                    size_mb = size_bytes / (1024 * 1024)
                    print(f"  âœ“ {filename:<25} {size_mb:>8.2f} MB")
            else:
                print(f"  âœ— {filename:<25} [FALTANTE]")
        
        # Contar bloques
        block_files = [f for f in os.listdir(output_dir) if f.startswith('block_')]
        block_size_bytes = sum(os.path.getsize(os.path.join(output_dir, f)) for f in block_files)
        total_size += block_size_bytes
        
        if block_size_bytes < 1024 * 1024:
            print(f"  âœ“ Bloques: {len(block_files)} archivos ({block_size_bytes/1024:.2f} KB)")
        else:
            print(f"  âœ“ Bloques: {len(block_files)} archivos ({block_size_bytes/(1024*1024):.2f} MB)")
        
        # TamaÃ±o total
        if total_size < 1024 * 1024:
            print(f"\nğŸ“Š TamaÃ±o total del Ã­ndice: {total_size/1024:.2f} KB")
        else:
            print(f"\nğŸ“Š TamaÃ±o total del Ã­ndice: {total_size/(1024*1024):.2f} MB")
        
        print("\n" + "=" * 80)
        print("ğŸ¯ PRÃ“XIMOS PASOS:")
        print("=" * 80)
        print("1. Ejecuta el sistema de pruebas:")
        print("   python text_search/test_complete_search.py")
        print("\n2. O prueba una bÃºsqueda rÃ¡pida:")
        print("   from text_search.cosine_search import CosineSearch")
        print("   searcher = CosineSearch(index_dir='data/spimi_blocks')")
        print("   results = searcher.search(['tu', 'consulta'])")
        print("=" * 80)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Error durante la construcciÃ³n: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Flujo principal interactivo"""
    print("\n" + "=" * 80)
    print("ğŸ” CONSTRUCTOR DE ÃNDICE SPIMI DESDE CSV")
    print("Proyecto 2 - Base de Datos II")
    print("=" * 80)
    
    # Paso 1: Listar CSVs disponibles
    print("\nğŸ“‚ Buscando archivos CSV...")
    csv_files = list_available_csvs()
    
    if not csv_files:
        print("âŒ No se encontraron archivos CSV en el proyecto")
        print("\nğŸ’¡ Copia tu CSV a una de estas carpetas:")
        print("   â€¢ postman/")
        print("   â€¢ datasets/")
        print("   â€¢ raÃ­z del proyecto")
        return
    
    print(f"\nâœ“ {len(csv_files)} archivo(s) CSV encontrado(s):")
    for i, csv_file in enumerate(csv_files, 1):
        size_mb = os.path.getsize(csv_file) / (1024 * 1024)
        print(f"  {i}. {csv_file} ({size_mb:.2f} MB)")
    
    # Paso 2: Seleccionar CSV
    print("\nğŸ“ Selecciona un archivo CSV:")
    try:
        choice = int(input("NÃºmero: ").strip())
        if choice < 1 or choice > len(csv_files):
            print("âŒ OpciÃ³n invÃ¡lida")
            return
        
        csv_path = csv_files[choice - 1]
        
    except ValueError:
        print("âŒ Entrada invÃ¡lida")
        return
    
    # Paso 3: Preview y seleccionar columnas
    headers = preview_csv(csv_path)
    if not headers:
        return
    
    text_columns = select_text_columns(headers)
    if not text_columns:
        return
    
    # Paso 4: ConfiguraciÃ³n adicional
    print("\nâš™ï¸  CONFIGURACIÃ“N ADICIONAL:")
    
    # Idioma
    print("\nğŸŒ Idioma para stopwords:")
    print("  1. English (inglÃ©s)")
    print("  2. Spanish (espaÃ±ol)")
    lang_choice = input("Selecciona (default: 1): ").strip()
    language = 'spanish' if lang_choice == '2' else 'english'
    
    # LÃ­mite de documentos
    print("\nğŸ“Š Â¿CuÃ¡ntos documentos procesar?")
    print("  â€¢ Presiona Enter para procesar TODOS")
    print("  â€¢ O escribe un nÃºmero (ej: 1000 para prueba rÃ¡pida)")
    max_docs_input = input("NÃºmero de documentos: ").strip()
    max_docs = int(max_docs_input) if max_docs_input.isdigit() else None
    
    # TamaÃ±o de bloque
    print("\nğŸ’¾ TamaÃ±o de bloque en RAM:")
    print("  â€¢ 50 MB - Para RAM limitada")
    print("  â€¢ 100 MB - Recomendado (default)")
    print("  â€¢ 200 MB - Para mÃ¡s velocidad")
    block_input = input("MB (default: 100): ").strip()
    block_size = int(block_input) if block_input.isdigit() else 100
    
    # ConfirmaciÃ³n
    print("\n" + "=" * 80)
    print("ğŸ“‹ RESUMEN:")
    print("=" * 80)
    print(f"Archivo: {csv_path}")
    print(f"Columnas: {', '.join(text_columns)}")
    print(f"Idioma: {language}")
    print(f"Documentos: {'TODOS' if not max_docs else max_docs}")
    print(f"TamaÃ±o bloque: {block_size} MB")
    print("=" * 80)
    
    confirm = input("\nÂ¿Proceder con la construcciÃ³n? (s/n): ").strip().lower()
    if confirm != 's':
        print("âŒ OperaciÃ³n cancelada")
        return
    
    # Paso 5: Construir Ã­ndice
    success = build_index_from_csv(
        csv_path=csv_path,
        text_columns=text_columns,
        output_dir='data/spimi_blocks',
        block_size_mb=block_size,
        max_docs=max_docs,
        language=language
    )
    
    if success:
        print("\nğŸ‰ Â¡Ãndice construido exitosamente!")
    else:
        print("\nâŒ Hubo errores durante la construcciÃ³n")


if __name__ == "__main__":
    main()
